{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1Z6Wtb_jisbA"
   },
   "source": [
    "##### Copyright 2019 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "QUyRGn9riopB"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H1yCdGFW4j_F"
   },
   "source": [
    "# 预创建的 Estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PS6_yKSoyLAl"
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://tensorflow.google.cn/tutorials/estimator/premade\"><img src=\"https://tensorflow.google.cn/images/tf_logo_32px.png\" />在 tensorFlow.google.cn 上查看</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/zh-cn/tutorials/estimator/premade.ipynb\"><img src=\"https://tensorflow.google.cn/images/colab_logo_32px.png\" />在 Google Colab 中运行</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/zh-cn/tutorials/estimator/premade.ipynb\"><img src=\"https://tensorflow.google.cn/images/GitHub-Mark-32px.png\" />在 GitHub 上查看源代码</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/zh-cn/tutorials/estimator/premade.ipynb\"><img src=\"https://tensorflow.google.cn/images/download_logo_32px.png\" />下载 notebook</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FgdA9XE5ZCS3"
   },
   "source": [
    "Note: 我们的 TensorFlow 社区翻译了这些文档。因为社区翻译是尽力而为， 所以无法保证它们是最准确的，并且反映了最新的\n",
    "[官方英文文档](https://www.tensorflow.org/?hl=en)。如果您有改进此翻译的建议， 请提交 pull request 到\n",
    "[tensorflow/docs](https://github.com/tensorflow/docs) GitHub 仓库。要志愿地撰写或者审核译文，请加入\n",
    "[docs-zh-cn@tensorflow.org Google Group](https://groups.google.com/a/tensorflow.org/forum/#!forum/docs-zh-cn)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R4YZ_ievcY7p"
   },
   "source": [
    "本教程将向您展示如何使用 Estimators 解决 Tensorflow 中的鸢尾花（Iris）分类问题。Estimator 是 Tensorflow 完整模型的高级表示，它被设计用于轻松扩展和异步训练。更多细节请参阅 [Estimators](https://tensorflow.google.cn/guide/estimator)。\n",
    "\n",
    "请注意，在 Tensorflow 2.0 中，[Keras API](https://tensorflow.google.cn/guide/keras) 可以完成许多相同的任务，而且被认为是一个更易学习的API。如果您刚刚开始入门，我们建议您从 Keras 开始。有关 Tensorflow 2.0 中可用高级API的更多信息，请参阅 [Keras标准化](https://medium.com/tensorflow/standardizing-on-keras-guidance-on-high-level-apis-in-tensorflow-2-0-bad2b04c819a)。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8IFct0yedsTy"
   },
   "source": [
    "## 首先要做的事\n",
    "\n",
    "为了开始，您将首先导入 Tensorflow 和一系列您需要的库。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jPo5bQwndr9P"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ronyang/.pyenv/versions/anaconda3-5.0.1/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c5w4m5gncnGh"
   },
   "source": [
    "## 数据集\n",
    "\n",
    "本文档中的示例程序构建并测试了一个模型，该模型根据[花萼](https://en.wikipedia.org/wiki/Sepal)和[花瓣](https://en.wikipedia.org/wiki/Petal)的大小将鸢尾花分成三种物种。\n",
    "\n",
    "您将使用鸢尾花数据集训练模型。该数据集包括四个特征和一个[标签](https://developers.google.com/machine-learning/glossary/#label)。这四个特征确定了单个鸢尾花的以下植物学特征：\n",
    "\n",
    "* 花萼长度\n",
    "* 花萼宽度\n",
    "* 花瓣长度\n",
    "* 花瓣宽度\n",
    "\n",
    "根据这些信息，您可以定义一些有用的常量来解析数据：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "lSyrXp_He_UE"
   },
   "outputs": [],
   "source": [
    "CSV_COLUMN_NAMES = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth', 'Species']\n",
    "SPECIES = ['Setosa', 'Versicolor', 'Virginica']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j6mTfIQzfC9w"
   },
   "source": [
    "接下来，使用 Keras 与 Pandas 下载并解析鸢尾花数据集。注意为训练和测试保留不同的数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PumyCN8VdGGc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\n",
      "8192/2194 [================================================================================================================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\n",
      "8192/573 [============================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "train_path = tf.keras.utils.get_file(\n",
    "    \"iris_training.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\")\n",
    "test_path = tf.keras.utils.get_file(\n",
    "    \"iris_test.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\")\n",
    "\n",
    "train = pd.read_csv(train_path, names=CSV_COLUMN_NAMES, header=0)\n",
    "test = pd.read_csv(test_path, names=CSV_COLUMN_NAMES, header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wHFxNLszhQjz"
   },
   "source": [
    "通过检查数据您可以发现有四列浮点型特征和一列 int32 型标签。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WOJt-ML4hAwI"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLength</th>\n",
       "      <th>SepalWidth</th>\n",
       "      <th>PetalLength</th>\n",
       "      <th>PetalWidth</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLength  SepalWidth  PetalLength  PetalWidth  Species\n",
       "0          6.4         2.8          5.6         2.2        2\n",
       "1          5.0         2.3          3.3         1.0        1\n",
       "2          4.9         2.5          4.5         1.7        2\n",
       "3          4.9         3.1          1.5         0.1        0\n",
       "4          5.7         3.8          1.7         0.3        0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jQJEYfVvfznP"
   },
   "source": [
    "对于每个数据集都分割出标签，模型将被训练来预测这些标签。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sSaJNGeaZCTG"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Species'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.0.1/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2645\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2646\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Species'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-d2a00ff04244>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Species'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Species'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# 标签列现已从数据中删除\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.0.1/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mpop\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    788\u001b[0m         \u001b[0;36m3\u001b[0m  \u001b[0mmonkey\u001b[0m        \u001b[0mNaN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m         \"\"\"\n\u001b[0;32m--> 790\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    791\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.0.1/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2798\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2799\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2800\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2801\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2802\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.0.1/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2646\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2648\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2649\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2650\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Species'"
     ]
    }
   ],
   "source": [
    "train_y = train.pop('Species')\n",
    "test_y = test.pop('Species')\n",
    "\n",
    "# 标签列现已从数据中删除\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jZx1L_1Vcmxv"
   },
   "source": [
    "## Estimator 编程概述\n",
    "\n",
    "现在您已经设定好了数据，您可以使用 Tensorflow Estimator 定义模型。Estimator 是从 `tf.estimator.Estimator` 中派生的任何类。Tensorflow提供了一组`tf.estimator`(例如，`LinearRegressor`)来实现常见的机器学习算法。此外，您可以编写您自己的[自定义 Estimator](https://tensorflow.google.cn/guide/custom_estimators)。入门阶段我们建议使用预创建的 Estimator。\n",
    "\n",
    "为了编写基于预创建的 Estimator 的 Tensorflow 项目，您必须完成以下工作：\n",
    "\n",
    "* 创建一个或多个输入函数\n",
    "* 定义模型的特征列\n",
    "* 实例化一个 Estimator，指定特征列和各种超参数。\n",
    "* 在 Estimator 对象上调用一个或多个方法，传递合适的输入函数以作为数据源。\n",
    "\n",
    "我们来看看这些任务是如何在鸢尾花分类中实现的。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2OcguDfBcmmg"
   },
   "source": [
    "## 创建输入函数\n",
    "\n",
    "您必须创建输入函数来提供用于训练、评估和预测的数据。\n",
    "\n",
    "**输入函数**是一个返回 `tf.data.Dataset` 对象的函数，此对象会输出下列含两个元素的元组：\n",
    "\n",
    "* [`features`](https://developers.google.com/machine-learning/glossary/#feature)——Python字典，其中：\n",
    "    * 每个键都是特征名称\n",
    "    * 每个值都是包含此特征所有值的数组\n",
    "* `label` 包含每个样本的[标签](https://developers.google.com/machine-learning/glossary/#label)的值的数组。\n",
    "\n",
    "为了向您展示输入函数的格式，请查看下面这个简单的实现：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "nzr5vRr5caGF"
   },
   "outputs": [],
   "source": [
    "def input_evaluation_set():\n",
    "    features = {'SepalLength': np.array([6.4, 5.0]),\n",
    "                'SepalWidth':  np.array([2.8, 2.3]),\n",
    "                'PetalLength': np.array([5.6, 3.3]),\n",
    "                'PetalWidth':  np.array([2.2, 1.0])}\n",
    "    labels = np.array([2, 1])\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NpXvGjfnjHgY"
   },
   "source": [
    "您的输入函数可以以您喜欢的方式生成 `features` 字典与 `label` 列表。但是，我们建议使用 Tensorflow 的 [Dataset API](https://tensorflow.google.cn/guide/datasets)，该 API 可以用来解析各种类型的数据。\n",
    "\n",
    "Dataset API 可以为您处理很多常见情况。例如，使用 Dataset API，您可以轻松地从大量文件中并行读取记录，并将它们合并为单个数据流。\n",
    "\n",
    "为了简化此示例，我们将使用 [pandas](https://pandas.pydata.org/) 加载数据，并利用此内存数据构建输入管道。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "T20u1anCi8NP"
   },
   "outputs": [],
   "source": [
    "def input_fn(features, labels, training=True, batch_size=256):\n",
    "    \"\"\"An input function for training or evaluating\"\"\"\n",
    "    # 将输入转换为数据集。\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "\n",
    "    # 如果在训练模式下混淆并重复数据。\n",
    "    if training:\n",
    "        dataset = dataset.shuffle(1000).repeat()\n",
    "    \n",
    "    return dataset.batch(batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xIwcFT4MlZEi"
   },
   "source": [
    "## 定义特征列（feature columns）\n",
    "\n",
    "[**特征列（feature columns）**](https://developers.google.com/machine-learning/glossary/#feature_columns)是一个对象，用于描述模型应该如何使用特征字典中的原始输入数据。当您构建一个 Estimator 模型的时候，您会向其传递一个特征列的列表，其中包含您希望模型使用的每个特征。`tf.feature_column` 模块提供了许多为模型表示数据的选项。\n",
    "\n",
    "对于鸢尾花问题，4 个原始特征是数值，因此我们将构建一个特征列的列表，以告知 Estimator 模型将 4 个特征都表示为 32 位浮点值。故创建特征列的代码如下所示：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "ZTTriO8FlSML"
   },
   "outputs": [],
   "source": [
    "# 特征列描述了如何使用输入。\n",
    "my_feature_columns = []\n",
    "for key in train.keys():\n",
    "    my_feature_columns.append(tf.feature_column.numeric_column(key=key))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jpKkhMoZljco"
   },
   "source": [
    "特征列可能比上述示例复杂得多。您可以从[指南](https://tensorflow.google.cn/guide/feature_columns)获取更多关于特征列的信息。\n",
    "\n",
    "我们已经介绍了如何使模型表示原始特征，现在您可以构建 Estimator 了。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kuE59XHEl22K"
   },
   "source": [
    "## 实例化 Estimator\n",
    "\n",
    "鸢尾花为题是一个经典的分类问题。幸运的是，Tensorflow 提供了几个预创建的 Estimator 分类器，其中包括：\n",
    "\n",
    "* `tf.estimator.DNNClassifier` 用于多类别分类的深度模型\n",
    "* `tf.estimator.DNNLinearCombinedClassifier` 用于广度与深度模型\n",
    "* `tf.estimator.LinearClassifier` 用于基于线性模型的分类器\n",
    "\n",
    "对于鸢尾花问题，`tf.estimator.DNNClassifier` 似乎是最好的选择。您可以这样实例化该 Estimator：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qnf4o2V5lcPn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpxuu8e19q\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpxuu8e19q', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "# 构建一个拥有两个隐层，隐藏节点分别为 30 和 10 的深度神经网络。\n",
    "classifier = tf.estimator.DNNClassifier(\n",
    "    feature_columns=my_feature_columns,\n",
    "    # 隐层所含结点数量分别为 30 和 10.\n",
    "    hidden_units=[30, 10],\n",
    "    # 模型必须从三个类别中做出选择。\n",
    "    n_classes=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tzzt5nUpmEe3"
   },
   "source": [
    " ## 训练、评估和预测\n",
    "\n",
    "我们已经有一个 Estimator 对象，现在可以调用方法来执行下列操作：\n",
    "\n",
    "* 训练模型。\n",
    "* 评估经过训练的模型。\n",
    "* 使用经过训练的模型进行预测。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rnihuLdWmE75"
   },
   "source": [
    "### 训练模型\n",
    "\n",
    "通过调用 Estimator 的 `Train` 方法来训练模型，如下所示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4jW08YtPl1iS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ronyang/.pyenv/versions/anaconda3-5.0.1/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /home/ronyang/.pyenv/versions/anaconda3-5.0.1/lib/python3.6/site-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:From /home/ronyang/.pyenv/versions/anaconda3-5.0.1/lib/python3.6/site-packages/tensorflow_core/python/keras/optimizer_v2/adagrad.py:103: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpxuu8e19q/model.ckpt.\n",
      "INFO:tensorflow:loss = 1.1818092, step = 0\n",
      "INFO:tensorflow:global_step/sec: 286.842\n",
      "INFO:tensorflow:loss = 0.8924533, step = 100 (0.350 sec)\n",
      "INFO:tensorflow:global_step/sec: 387.53\n",
      "INFO:tensorflow:loss = 0.83853734, step = 200 (0.259 sec)\n",
      "INFO:tensorflow:global_step/sec: 374.53\n",
      "INFO:tensorflow:loss = 0.79180366, step = 300 (0.267 sec)\n",
      "INFO:tensorflow:global_step/sec: 381.433\n",
      "INFO:tensorflow:loss = 0.76277196, step = 400 (0.262 sec)\n",
      "INFO:tensorflow:global_step/sec: 368.542\n",
      "INFO:tensorflow:loss = 0.7354562, step = 500 (0.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 371.17\n",
      "INFO:tensorflow:loss = 0.70701444, step = 600 (0.270 sec)\n",
      "INFO:tensorflow:global_step/sec: 365.181\n",
      "INFO:tensorflow:loss = 0.68262285, step = 700 (0.274 sec)\n",
      "INFO:tensorflow:global_step/sec: 369.254\n",
      "INFO:tensorflow:loss = 0.6659244, step = 800 (0.270 sec)\n",
      "INFO:tensorflow:global_step/sec: 380.68\n",
      "INFO:tensorflow:loss = 0.64679754, step = 900 (0.263 sec)\n",
      "INFO:tensorflow:global_step/sec: 357.005\n",
      "INFO:tensorflow:loss = 0.6325724, step = 1000 (0.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 416.683\n",
      "INFO:tensorflow:loss = 0.6189921, step = 1100 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 375.634\n",
      "INFO:tensorflow:loss = 0.60124874, step = 1200 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 478.483\n",
      "INFO:tensorflow:loss = 0.5877007, step = 1300 (0.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 364.675\n",
      "INFO:tensorflow:loss = 0.5788323, step = 1400 (0.275 sec)\n",
      "INFO:tensorflow:global_step/sec: 506.253\n",
      "INFO:tensorflow:loss = 0.5700482, step = 1500 (0.198 sec)\n",
      "INFO:tensorflow:global_step/sec: 355.307\n",
      "INFO:tensorflow:loss = 0.55977535, step = 1600 (0.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 359.278\n",
      "INFO:tensorflow:loss = 0.55431235, step = 1700 (0.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 363.618\n",
      "INFO:tensorflow:loss = 0.54607546, step = 1800 (0.275 sec)\n",
      "INFO:tensorflow:global_step/sec: 368.334\n",
      "INFO:tensorflow:loss = 0.5396653, step = 1900 (0.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.13\n",
      "INFO:tensorflow:loss = 0.5265691, step = 2000 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 340.464\n",
      "INFO:tensorflow:loss = 0.5176432, step = 2100 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 380.031\n",
      "INFO:tensorflow:loss = 0.51363826, step = 2200 (0.263 sec)\n",
      "INFO:tensorflow:global_step/sec: 520.55\n",
      "INFO:tensorflow:loss = 0.49643624, step = 2300 (0.192 sec)\n",
      "INFO:tensorflow:global_step/sec: 349.25\n",
      "INFO:tensorflow:loss = 0.49028784, step = 2400 (0.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 498.343\n",
      "INFO:tensorflow:loss = 0.48251587, step = 2500 (0.201 sec)\n",
      "INFO:tensorflow:global_step/sec: 362.822\n",
      "INFO:tensorflow:loss = 0.47139305, step = 2600 (0.275 sec)\n",
      "INFO:tensorflow:global_step/sec: 356.904\n",
      "INFO:tensorflow:loss = 0.47401497, step = 2700 (0.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.098\n",
      "INFO:tensorflow:loss = 0.47313595, step = 2800 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 369.975\n",
      "INFO:tensorflow:loss = 0.45244038, step = 2900 (0.271 sec)\n",
      "INFO:tensorflow:global_step/sec: 478.97\n",
      "INFO:tensorflow:loss = 0.4610871, step = 3000 (0.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 346.761\n",
      "INFO:tensorflow:loss = 0.45050332, step = 3100 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 363.364\n",
      "INFO:tensorflow:loss = 0.43537432, step = 3200 (0.274 sec)\n",
      "INFO:tensorflow:global_step/sec: 362.523\n",
      "INFO:tensorflow:loss = 0.43900856, step = 3300 (0.277 sec)\n",
      "INFO:tensorflow:global_step/sec: 443.478\n",
      "INFO:tensorflow:loss = 0.43357995, step = 3400 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 357.423\n",
      "INFO:tensorflow:loss = 0.4317186, step = 3500 (0.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 363.936\n",
      "INFO:tensorflow:loss = 0.42582068, step = 3600 (0.275 sec)\n",
      "INFO:tensorflow:global_step/sec: 536.124\n",
      "INFO:tensorflow:loss = 0.4289648, step = 3700 (0.186 sec)\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 3705 vs previous value: 3705. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "INFO:tensorflow:global_step/sec: 360.59\n",
      "INFO:tensorflow:loss = 0.4114818, step = 3800 (0.277 sec)\n",
      "INFO:tensorflow:global_step/sec: 464.589\n",
      "INFO:tensorflow:loss = 0.41210282, step = 3900 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 362.615\n",
      "INFO:tensorflow:loss = 0.40967083, step = 4000 (0.276 sec)\n",
      "INFO:tensorflow:global_step/sec: 339.957\n",
      "INFO:tensorflow:loss = 0.4001136, step = 4100 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 384.602\n",
      "INFO:tensorflow:loss = 0.4000783, step = 4200 (0.259 sec)\n",
      "INFO:tensorflow:global_step/sec: 369.466\n",
      "INFO:tensorflow:loss = 0.38655195, step = 4300 (0.271 sec)\n",
      "INFO:tensorflow:global_step/sec: 369.04\n",
      "INFO:tensorflow:loss = 0.3841964, step = 4400 (0.270 sec)\n",
      "INFO:tensorflow:global_step/sec: 365.295\n",
      "INFO:tensorflow:loss = 0.3759294, step = 4500 (0.274 sec)\n",
      "INFO:tensorflow:global_step/sec: 356.969\n",
      "INFO:tensorflow:loss = 0.39253694, step = 4600 (0.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 559.443\n",
      "INFO:tensorflow:loss = 0.37664318, step = 4700 (0.178 sec)\n",
      "INFO:tensorflow:global_step/sec: 350.108\n",
      "INFO:tensorflow:loss = 0.36985117, step = 4800 (0.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 365.601\n",
      "INFO:tensorflow:loss = 0.37821823, step = 4900 (0.274 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into /tmp/tmpxuu8e19q/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.36696246.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifierV2 at 0x7f74b057b940>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 训练模型。\n",
    "classifier.train(\n",
    "    input_fn=lambda: input_fn(train, train_y, training=True),\n",
    "    steps=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ybiTFDmlmes8"
   },
   "source": [
    "注意将 ` input_fn` 调用封装在 [`lambda`](https://docs.python.org/3/tutorial/controlflow.html) 中以获取参数，同时提供不带参数的输入函数，如 Estimator 所预期的那样。`step` 参数告知该方法在训练多少步后停止训练。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HNvJLH8hmsdf"
   },
   "source": [
    "### 评估经过训练的模型\n",
    "\n",
    "现在模型已经经过训练，您可以获取一些关于模型性能的统计信息。代码块将在测试数据上对经过训练的模型的准确率（accuracy）进行评估：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A169XuO4mKxF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-06-24T10:37:31Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpxuu8e19q/model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.32127s\n",
      "INFO:tensorflow:Finished evaluation at 2020-06-24-10:37:31\n",
      "INFO:tensorflow:Saving dict for global step 5000: accuracy = 0.93333334, average_loss = 0.42993486, global_step = 5000, loss = 0.42993486\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: /tmp/tmpxuu8e19q/model.ckpt-5000\n",
      "\n",
      "Test set accuracy: 0.933\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eval_result = classifier.evaluate(\n",
    "    input_fn=lambda: input_fn(test, test_y, training=False))\n",
    "\n",
    "print('\\nTest set accuracy: {accuracy:0.3f}\\n'.format(**eval_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VnPMP5EHph17"
   },
   "source": [
    "与对 `train` 方法的调用不同，我们没有传递 `steps` 参数来进行评估。用于评估的 `input_fn` 只生成一个 [epoch](https://developers.google.com/machine-learning/glossary/#epoch) 的数据。\n",
    "\n",
    "`eval_result` 字典亦包含 `average_loss`（每个样本的平均误差），`loss`（每个 mini-batch 的平均误差）与 Estimator 的 `global_step`（经历的训练迭代次数）值。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ur624ibpp52X"
   },
   "source": [
    "### 利用经过训练的模型进行预测（推理）\n",
    "\n",
    "我们已经有一个经过训练的模型，可以生成准确的评估结果。我们现在可以使用经过训练的模型，根据一些无标签测量结果预测鸢尾花的品种。与训练和评估一样，我们使用单个函数调用进行预测："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "wltc0jpgng38"
   },
   "outputs": [],
   "source": [
    "# 由模型生成预测\n",
    "expected = ['Setosa', 'Versicolor', 'Virginica']\n",
    "predict_x = {\n",
    "    'SepalLength': [5.1, 5.9, 6.9],\n",
    "    'SepalWidth': [3.3, 3.0, 3.1],\n",
    "    'PetalLength': [1.7, 4.2, 5.4],\n",
    "    'PetalWidth': [0.5, 1.5, 2.1],\n",
    "}\n",
    "\n",
    "def input_fn(features, batch_size=256):\n",
    "    \"\"\"An input function for prediction.\"\"\"\n",
    "    # 将输入转换为无标签数据集。\n",
    "    return tf.data.Dataset.from_tensor_slices(dict(features)).batch(batch_size)\n",
    "\n",
    "predictions = classifier.predict(\n",
    "    input_fn=lambda: input_fn(predict_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JsETKQo0rHvi"
   },
   "source": [
    "`predict` 方法返回一个 Python 可迭代对象，为每个样本生成一个预测结果字典。以下代码输出了一些预测及其概率："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Efm4mLzkrCxp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpxuu8e19q/model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "Prediction is \"Setosa\" (84.2%), expected \"Setosa\"\n",
      "Prediction is \"Versicolor\" (53.8%), expected \"Versicolor\"\n",
      "Prediction is \"Virginica\" (61.8%), expected \"Virginica\"\n"
     ]
    }
   ],
   "source": [
    "for pred_dict, expec in zip(predictions, expected):\n",
    "    class_id = pred_dict['class_ids'][0]\n",
    "    probability = pred_dict['probabilities'][class_id]\n",
    "\n",
    "    print('Prediction is \"{}\" ({:.1f}%), expected \"{}\"'.format(\n",
    "        SPECIES[class_id], 100 * probability, expec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "premade.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
